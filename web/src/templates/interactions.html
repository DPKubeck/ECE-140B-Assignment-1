<!doctype html>
<html lang="en">

  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Page Info -->
    <title>Daniel Kubeck's TheraBot</title>
    <meta name="author" content="Daniel Kubeck">
    <meta name="description" content="Hosted with Style!">

    <link rel="stylesheet" type="text/css" href="css/agile.css">
  </head>

  <body>

    <div class='hero'>
      <h1> TheraBot Home </h1>
      <p> A helpful desk robot with character! </p>
      <!-- http://164.92.122.126/XXXXXX -->
      <a class="linkbutton" href="/"> Home </a>
      <a class="linkbutton" href="/product"> Product Page </a>
      <a class="linkbutton" href="/kvp"> KVP </a>
      <a class="linkbutton" href="/ui"> UI </a>
      <a class="linkbutton" href="/features"> Features </a>
      <a class="linkbutton" href="/interactions"> Interactions </a>
    </div>

    <section class='padding-responsive'>

      <h2 class='bordered'> Interactions </h2>
      
      <p> The primary way of interacting with TheraBot is with your voice (and ears). You will be able to speak to the TheraBot device, and with that, TheraBot is able to understand what you said and think of a response, and then say that response back to you. Since TheraBot is based more on fun interactions with it, many of these interactions won't necessarily have significant productive weight. The main point of them is to engage with the user and make them smile or laugh because of the joke, story, or response that was said. However, we do want to improve these after the MVP by making TheraBot able to audibly take notes and reminders for you, allowing the device to both be fun and encouraging, but also help you be more productive in your day. </p>

      <p> The secondary way of interacting with TheraBot is through the screen. TheraBot has a screen that it uses as its eyes (but also can be used to display other information if needed). Research shows that eyes hold the most information on the face what it comes to body language and understanding another person, so we utilize this in TheraBot to help the device feel more human-like and improve the quality and believability of the interactions. TheraBot is able to use this screen as its eyes to both display emotions on it as well as change its eyes as a human would when talking. This allows users to be able to "read" TheraBot's body language, instead of just having verbal interactions with the device. </p>

      <p> One method of interaction we think is beyond our MVP but would eventually like to incorporate is physical interaction. Our idea is that TheraBot has a touch sensor on its body, allowing the user to tap on, swipe across, or even pet TheraBot, with each of the interactions having different outcomes. This touch sensor would likely be on the top of the device, and TheraBot will know when it has been touched and be able to respond accordingly. Beyond this, adding an accelerometer would add to the physical interactivity of the device. TheraBot would be able to know when you sit at your desk, or if you pound down on it because you are angry. It would also be able to tell if it had been bumped. Both of these levels of physical interaction with the device build onto the human nature of it, and increase the immersion and believability the user has when interacting with TheraBot. </p>
      
      <p> The last main way of interacting with TheraBot is time. In our MVP, the effect of this will be limited, but with further development, we would want TheraBot to be able to learn. Having this ability allows TheraBot to customize itself to be a better friend for the user and make the interactions it has more fun. It would also be able to learn tendencies and be able to predict things, such as when you get home or when you wake it. All of this allows the user to interact in new ways with TheraBot, instead of just being limited to direct communication with it. </p>

    </section>

  </body>
</html>